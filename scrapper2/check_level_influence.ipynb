{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cf18e9a",
   "metadata": {},
   "source": [
    "# Preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "19ca24f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Plik z dzielnicami utworzony\n",
      "✅ Pliki train/test utworzone\n",
      "✅ Dane przetworzone i zapisane jako ./lux/lux_3k_district_train.csv oraz ./lux/lux_3k_district_test.csv\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "sys.path.append('../model/src')\n",
    "\n",
    "from add_district import add_district\n",
    "from create_train_test import create_train_test\n",
    "from data_preprocessing import preprocess_data\n",
    "from util import get_filename_and_extension\n",
    "\n",
    "\n",
    "source_filename = './lux/lux_3k.csv'\n",
    "filename = add_district(source_filename)\n",
    "print(\"✅ Plik z dzielnicami utworzony\")\n",
    "\n",
    "train_filename, test_filename = create_train_test(filename, test_size=30)\n",
    "print(\"✅ Pliki train/test utworzone\")\n",
    "\n",
    "train = pd.read_csv(train_filename)\n",
    "test = pd.read_csv(test_filename)\n",
    "\n",
    "# # Przetworzenie i zapis zestawów train/test\n",
    "name, _ = get_filename_and_extension(source_filename)\n",
    "config_filename = f\"{name}.pkl\"\n",
    "train = preprocess_data(train, is_train=True, config_filename=config_filename)\n",
    "test = preprocess_data(test, is_train=False, config_filename=config_filename)\n",
    "\n",
    "# Porównanie kolumn i dodanie brakujących kolumn z zerami\n",
    "for col in train.columns:\n",
    "    if col not in test.columns:\n",
    "        test[col] = 0\n",
    "\n",
    "for col in test.columns:\n",
    "    if col not in train.columns:\n",
    "        train[col] = 0\n",
    "\n",
    "# Zapewnienie, że kolumny w train i test są w tej samej kolejności\n",
    "train = train[sorted(train.columns)]\n",
    "test = test[sorted(test.columns)]\n",
    "\n",
    "train.to_csv(train_filename, index=False)\n",
    "test.to_csv(test_filename, index=False)\n",
    "\n",
    "print(f\"✅ Dane przetworzone i zapisane jako {train_filename} oraz {test_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e246b62",
   "metadata": {},
   "source": [
    "# Load data\n",
    "Drop useless rows (without luxury level or price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "964aa7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows dropped for 'luxury_level' < 0: 762\n",
      "Rows dropped for 'price' < 0: 0\n",
      "Rows dropped for 'area' < 0: 84\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1475 entries, 0 to 2320\n",
      "Data columns (total 25 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   ad_type                        1475 non-null   object \n",
      " 1   area                           1475 non-null   float64\n",
      " 2   build_year                     1475 non-null   float64\n",
      " 3   building_floors                1475 non-null   float64\n",
      " 4   collage                        1475 non-null   object \n",
      " 5   distance_from_center           1475 non-null   float64\n",
      " 6   distance_from_other_expensive  1475 non-null   float64\n",
      " 7   floor                          1475 non-null   int64  \n",
      " 8   heating                        1328 non-null   object \n",
      " 9   location_district              1475 non-null   object \n",
      " 10  location_lat                   1475 non-null   float64\n",
      " 11  location_lon                   1475 non-null   float64\n",
      " 12  luxury_level                   1475 non-null   float64\n",
      " 13  market                         1475 non-null   object \n",
      " 14  ownership                      1290 non-null   object \n",
      " 15  price                          1475 non-null   float64\n",
      " 16  price_m2                       1475 non-null   float64\n",
      " 17  rooms                          1475 non-null   int64  \n",
      " 18  state                          1240 non-null   object \n",
      " 19  utilities_balkon               1475 non-null   int64  \n",
      " 20  utilities_oddzielna kuchnia    1475 non-null   int64  \n",
      " 21  utilities_piwnica              1475 non-null   int64  \n",
      " 22  utilities_pom. użytkowe        1475 non-null   int64  \n",
      " 23  utilities_taras                1475 non-null   int64  \n",
      " 24  utilities_winda                1475 non-null   int64  \n",
      "dtypes: float64(10), int64(8), object(7)\n",
      "memory usage: 299.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(train_filename, sep=',')\n",
    "\n",
    "initial_count = len(df)\n",
    "\n",
    "# Filter rows where 'luxury_level' is >= 0\n",
    "df = df[df['luxury_level'] >= 0]\n",
    "luxury_level_dropped = initial_count - len(df)\n",
    "\n",
    "# Filter rows where 'price' is >= 0\n",
    "initial_count = len(df)\n",
    "df = df[df['price'] >= 0]\n",
    "price_dropped = initial_count - len(df)\n",
    "\n",
    "# Filter rows where 'area' is >= 0\n",
    "initial_count = len(df)\n",
    "df = df[df['area'] >= 0]\n",
    "area_dropped = initial_count - len(df)\n",
    "\n",
    "# Display the counts of dropped rows\n",
    "print(f\"Rows dropped for 'luxury_level' < 0: {luxury_level_dropped}\")\n",
    "print(f\"Rows dropped for 'price' < 0: {price_dropped}\")\n",
    "print(f\"Rows dropped for 'area' < 0: {area_dropped}\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7dab1238",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../backend')\n",
    "\n",
    "from model import model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8e5277",
   "metadata": {},
   "source": [
    "# Convert csv to data requrired by model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b49f254d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import Series\n",
    "\n",
    "row = df.iloc[0]\n",
    "features = model._model.get_booster().feature_names\n",
    "n_features = len(features)\n",
    "\n",
    "def convert(row: Series) -> np.ndarray:\n",
    "    # print(f\"{row['state'] = }, {type(row['state']) = }\")\n",
    "    if pd.isna(row['heating']):\n",
    "        row['heating'] = 'urban'\n",
    "    if pd.isna(row['ownership']):\n",
    "        row['ownership'] = 'full_ownership'\n",
    "    if pd.isna(row['state']):\n",
    "        row['state'] = 'ready_to_use'\n",
    "    form_data = {}\n",
    "    # Categorical features\n",
    "    form_data[\"ad_type\"] = model._map(\"ad_type\", row['ad_type'])\n",
    "    form_data[\"heating\"] = model._map(\"heating\", row['heating'])\n",
    "    form_data[\"location_district\"] = model._map(\"location_district\", row['location_district'])\n",
    "    form_data[\"market\"] = model._map(\"market\", row['market'])\n",
    "    form_data[\"ownership\"] = model._map(\"ownership\", row['ownership'])\n",
    "    form_data[\"state\"] = model._map(\"state\", row['state'])\n",
    "\n",
    "\n",
    "    form_data[\"area\"] = row['area']\n",
    "    form_data[\"build_year\"] = row['build_year']\n",
    "    form_data[\"building_floors\"] = row['building_floors']\n",
    "    form_data[\"floor\"] = row['floor']\n",
    "\n",
    "    form_data[\"location_lat\"] = row['location_lat']\n",
    "    form_data[\"location_lon\"] = row['location_lon']\n",
    "    form_data[\"rooms\"] = row['rooms']\n",
    "    form_data[\"utilities_balkon\"] = int(row['utilities_balkon'])\n",
    "    form_data[\"utilities_oddzielna kuchnia\"] = int(row['utilities_oddzielna kuchnia'])\n",
    "    form_data[\"utilities_piwnica\"] = int(row['utilities_piwnica'])\n",
    "    form_data[\"utilities_pom. użytkowe\"] = int(row['utilities_piwnica'])\n",
    "    form_data[\"utilities_taras\"] = int(row['utilities_balkon'])\n",
    "    form_data[\"utilities_winda\"] = int(row['utilities_winda'])\n",
    "    # TODO: available in frontend but not used: available from\n",
    "    form_data[\"distance_from_center\"] = row['distance_from_center']\n",
    "    form_data[\"distance_from_other_expensive\"] = row['distance_from_other_expensive']\n",
    "\n",
    "    # Fill data_array with values from form_data using fetures array\n",
    "    data_array = np.zeros([n_features])\n",
    "    for i, feature in enumerate(features):\n",
    "        if feature in form_data:\n",
    "            data_array[i] = form_data[feature]\n",
    "        else:\n",
    "            raise ValueError(f\"Feature '{feature}' not found in form_data\")\n",
    "\n",
    "    # Reshape the 1D array to a 2D array (1 x 38) as required by XGBoost\n",
    "    data_array = np.reshape(data_array, (1, -1))\n",
    "    return data_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6e00abff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Predykcje zapisane do pliku ./lux/lux_3k_district_train_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "df_with_predictions = df.copy()\n",
    "df_with_predictions['prediction'] = 0.0\n",
    "\n",
    "name, _ = get_filename_and_extension(train_filename)\n",
    "out_filename = f\"{name}_predictions.csv\"\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    try:\n",
    "        data_array = convert(row)\n",
    "    except ValueError as e:\n",
    "        print(f\"Error processing row {index}: {e}\")\n",
    "        continue\n",
    "    prediction = model._model.predict(data_array)\n",
    "    df_with_predictions.at[index, 'prediction'] = prediction[0]\n",
    "    \n",
    "df_with_predictions = df_with_predictions[df_with_predictions['prediction'] > 0]\n",
    "df_with_predictions.to_csv(out_filename, index=False)\n",
    "print(f\"✅ Predykcje zapisane do pliku {out_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
